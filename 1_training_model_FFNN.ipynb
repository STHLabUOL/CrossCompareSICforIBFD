{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train FFNN model on any type of data, with or without linear preprocessing.<br>\n",
    "Script based on NNCancellation.py from https://github.com/abalatsoukas/fdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import fullduplex as fd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import os\n",
    "import pickle\n",
    "from models import FFNN_model\n",
    "\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Script Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TYPE = 'R' # R/H/W\n",
    "LIN_PREPROCESSING = True\n",
    "\n",
    "CHANNEL_LEN = 13\n",
    "TRAINING_RATIO = 0.9\n",
    "\n",
    "EXPORT_RESULTS = True\n",
    "PATH_EXPORT_RESULTS = 'comparison_results/new/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line disables the use of the GPU for training. The dataset is not large enough to get\n",
    "# significant gains from GPU training and, in fact, sometimes training can even be slower on\n",
    "# the GPU than on the CPU. Comment out to enable GPU use.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# Define system parameters\n",
    "params = {\n",
    "\t\t'samplingFreqMHz': 20,\t# Sampling frequency, required for correct scaling of PSD\n",
    "\t\t'hSILen': CHANNEL_LEN,\t\t\t# Self-interference channel length\n",
    "\t\t'pamaxordercanc': 7,\t# Maximum PA non-linearity order\n",
    "\t\t'trainingRatio': TRAINING_RATIO,\t# Ratio of total samples to use for training\n",
    "\t\t'dataOffset': 14,\t\t# Data offset to take transmitter-receiver misalignment into account\n",
    "\t\t'nHidden': 17,\t\t\t# Number of hidden layers in NN\n",
    "\t\t'nEpochs': 50,\t\t\t# Number of training epochs for NN training\n",
    "\t\t'learningRate': 0.004,\t# Learning rate for NN training\n",
    "\t\t'batchSize': 32,\t\t# Batch size for NN training\n",
    "\t\t}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DATA_TYPE == 'R':\n",
    "\n",
    "    x, y, noise, measuredNoisePower = fd.loadData(PATH_DATA_REAL, params)\n",
    "\n",
    "elif DATA_TYPE == 'H':\n",
    "\n",
    "    matlabVariables = sio.loadmat(PATH_DATA_SYNTH_HAMMERSTEIN+'/fileID0.mat')\n",
    "    x = np.squeeze(matlabVariables['sig_s'])[:TOTAL_SIGNAL_LENGTH]\n",
    "    y = np.squeeze(matlabVariables['sig_yH'])[:TOTAL_SIGNAL_LENGTH]\n",
    "    noise = np.squeeze(np.squeeze(matlabVariables['sig_yH']) - np.squeeze(matlabVariables['sig_x']))\n",
    "\n",
    "elif DATA_TYPE == 'W':\n",
    "\n",
    "    matlabVariables = sio.loadmat(PATH_DATA_SYNTH_WIENER+'/fileID0.mat')\n",
    "    x = np.squeeze(matlabVariables['sig_z'])[:TOTAL_SIGNAL_LENGTH]\n",
    "    y = np.squeeze(matlabVariables['sig_yW'])[:TOTAL_SIGNAL_LENGTH]\n",
    "    noise = np.squeeze(np.squeeze(matlabVariables['sig_yH']) - np.squeeze(matlabVariables['sig_x']))\n",
    "\n",
    "else:\n",
    "    raise ValueError('DATA_TYPE must be either \"R\", \"H\", or \"W\".')\n",
    "\n",
    "# remove mean\n",
    "y = y - np.mean(y)\n",
    "\n",
    "# Split into training and test sets\n",
    "trainingSamples = int(np.floor(x.size*params['trainingRatio']))\n",
    "x_train = x[0:trainingSamples]\n",
    "y_train = y[0:trainingSamples]\n",
    "x_test = x[trainingSamples:]\n",
    "y_test = y[trainingSamples:]\n",
    "\n",
    "y_test_orig = np.copy(y_test) # for later eval, untouched by lin. preproc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional Linear Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIN_PREPROCESSING:\n",
    "    \n",
    "    # Train-data\n",
    "    hLin = fd.SIestimationLinear(x_train, y_train, params)\n",
    "    y_train_lin = fd.SIcancellationLinear(x_train, hLin, params)\n",
    "    y_train = y_train - y_train_lin\n",
    "\n",
    "    # Test-data\n",
    "    y_test_lin = fd.SIcancellationLinear(x_test, hLin, params)\n",
    "    y_test = y_test - y_test_lin\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target normalization (regardless of whether lin. preproc. was applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yVar = np.var(y_train)\n",
    "y_train = y_train/np.sqrt(yVar)\n",
    "y_test = y_test/np.sqrt(yVar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-data\n",
    "x_train_real = np.reshape(np.array([x_train[i:i+CHANNEL_LEN].real for i in range(x_train.size-CHANNEL_LEN+1)]), (x_train.size-CHANNEL_LEN+1, CHANNEL_LEN))\n",
    "x_train_imag = np.reshape(np.array([x_train[i:i+CHANNEL_LEN].imag for i in range(x_train.size-CHANNEL_LEN+1)]), (x_train.size-CHANNEL_LEN+1, CHANNEL_LEN))\n",
    "x_train = np.zeros((x_train.size-CHANNEL_LEN+1, 2*CHANNEL_LEN))\n",
    "x_train[:,0:CHANNEL_LEN] = x_train_real\n",
    "x_train[:,CHANNEL_LEN:2*CHANNEL_LEN] = x_train_imag\n",
    "y_train = np.reshape(y_train[CHANNEL_LEN-1:], (y_train.size-CHANNEL_LEN+1, 1))\n",
    "\n",
    "# Test-data\n",
    "x_test_real = np.reshape(np.array([x_test[i:i+CHANNEL_LEN].real for i in range(x_test.size-CHANNEL_LEN+1)]), (x_test.size-CHANNEL_LEN+1, CHANNEL_LEN))\n",
    "x_test_imag = np.reshape(np.array([x_test[i:i+CHANNEL_LEN].imag for i in range(x_test.size-CHANNEL_LEN+1)]), (x_test.size-CHANNEL_LEN+1, CHANNEL_LEN))\n",
    "x_test = np.zeros((x_test.size-CHANNEL_LEN+1, 2*CHANNEL_LEN))\n",
    "x_test[:,0:CHANNEL_LEN] = x_test_real\n",
    "x_test[:,CHANNEL_LEN:2*CHANNEL_LEN] = x_test_imag\n",
    "y_test = np.reshape(y_test[CHANNEL_LEN-1:], (y_test.size-CHANNEL_LEN+1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FFNN_model(CHANNEL_LEN, params['nHidden'])\n",
    "adam = Adam(lr=params['learningRate'])\n",
    "model.compile(loss = \"mse\", optimizer = adam)\n",
    "\n",
    "##### Training #####\n",
    "# Step 2: train NN to do non-linear cancellation\n",
    "nEpochs = params['nEpochs']\n",
    "history = model.fit(x_train, [y_train.real, y_train.imag], epochs = nEpochs, batch_size = params['batchSize'], verbose=2, validation_data=(x_test, [y_test.real, y_test.imag]))\n",
    "\n",
    "##### Test #####\n",
    "# Do inference step\n",
    "pred = model.predict(x_test)\n",
    "y_test_pred = np.squeeze(pred[0] + 1j*pred[1], axis=1) # prev. named \"y_test_nl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'normal',\n",
    "        'weight' : 'regular',\n",
    "        'size'   : 14}\n",
    "\n",
    "mpl.rc('font', **font)\n",
    "\n",
    "\n",
    "# Calculate various signal powers\n",
    "noisePower = 10*np.log10(np.mean(np.abs(noise)**2))\n",
    "scalingConst = PSD_SCALING_CONST#np.power(10,-(measuredNoisePower-noisePower)/10)\n",
    "\n",
    "if not LIN_PREPROCESSING:\n",
    "    y_test_lin = 0*y_test_orig\n",
    "\n",
    "# Plot PSD and get signal powers\n",
    "fig, noisePower, yTestPower, yTestLinCancPower, yTestNonLinCancPower = fd.plotPSD(\n",
    "                                                                                y_test_orig[CHANNEL_LEN-1:]/np.sqrt(scalingConst), \n",
    "                                                                                y_test_lin[CHANNEL_LEN-1:]/np.sqrt(scalingConst), \n",
    "                                                                                y_test_pred/np.sqrt(scalingConst), \n",
    "                                                                                noise/np.sqrt(scalingConst), \n",
    "                                                                                params, \n",
    "                                                                                'NN', \n",
    "                                                                                yVar,\n",
    "                                                                        )\n",
    "\n",
    "# Print cancellation performance\n",
    "print('')\n",
    "print('The linear SI cancellation is: {:.2f} dB'.format(yTestPower-yTestLinCancPower))\n",
    "print('The non-linear SI cancellation is: {:.2f} dB'.format(yTestLinCancPower-yTestNonLinCancPower))\n",
    "print('The noise floor is: {:.2f} dBm'.format(noisePower))\n",
    "print('The distance from noise floor is: {:.2f} dB'.format(yTestNonLinCancPower-noisePower))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot learning curve\n",
    "plt.plot(np.arange(1,len(history.history['loss'])+1), -10*np.log10(history.history['loss']), 'bo-')\n",
    "plt.plot(np.arange(1,len(history.history['loss'])+1), -10*np.log10(history.history['val_loss']), 'ro-')\n",
    "plt.ylabel('Self-Interference Cancellation (dB)')\n",
    "plt.xlabel('Training Epoch')\n",
    "plt.legend(['Training Frame', 'Test Frame'], loc='lower right')\n",
    "plt.grid(which='major', alpha=0.25)\n",
    "plt.xlim([ 0, nEpochs+1 ])\n",
    "plt.xticks(range(1,nEpochs,2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_RESULTS:\n",
    "    file_name = PATH_EXPORT_RESULTS + 'data_' + DATA_TYPE + '_model_FFNN_linSIC_' + ('yes' if LIN_PREPROCESSING else 'no') + '.pkl'\n",
    "    confirm = input(f'Export as {file_name}? (yes/no)')\n",
    "    if confirm == 'yes':\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump({'y_test': y_test_orig[CHANNEL_LEN-1:], 'y_test_lin': y_test_lin[CHANNEL_LEN-1:], 'y_test_nl': y_test_pred, 'noise': noise, 'yVar': yVar, 'chanLen': params['hSILen']}, f)\n",
    "        print('File saved.')\n",
    "    else:\n",
    "        print('File not saved.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enzner_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
